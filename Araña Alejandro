###spider para web scrapping
import scrapy
from scrapy.crawler import CrawlerProcess

# Crear la araña
class covid_hunter(scrapy.Spider):
    
    # Asignamos un nombre a la araña.
    name = "covid_hunter"
    
    # Indicamos la url que queremos analizar en primer lugar.
    def start_requests(self):
        urls = ['page1','page2']
        
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)
  
    # Definimos el analizador.
    def parse(self, response):
        page = response.url.split("/")[-2]
        filename = 'covid_hunter-%s.html' % page
        #trabajar con xpath
        for spider in response.xpath(''):
            yield {'área(name/data-code)': results.extract()}
        #trabajar con css
        for spider in response.css(''):
            yield {'': pider.css('').get()
                  '': pider.css('').get(),
                  '': pider.css('').getall(),
                  }
        with open(filename,'wb') as f:
            f.write(response.body)
        self.log('Saved file %s' % filename)

        
if __name__ == "__main__":

    # Creamos un crawler.
    process = CrawlerProcess({
        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',
        'DOWNLOAD_HANDLERS': {'s3': None},
        'LOG_ENABLED': True
    })

    # Inicializamos el crawler con nuestra araña.
    process.crawl(covid_hunter)
    
    # Lanzamos la araña.
    process.start()
